{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file_name = 'page11.jpg' \n",
    "image = cv2.imread(image_file_name)\n",
    "\n",
    "# gray convertion\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "abs_grad_x = cv2.convertScaleAbs(grad_x)\n",
    "abs_grad_y = cv2.convertScaleAbs(grad_y)\n",
    "\n",
    "# threshold\n",
    "thresh_x = cv2.threshold(abs_grad_x, 0, 255,  cv2.THRESH_OTSU)[1]\n",
    "thresh_y = cv2.threshold(abs_grad_y, 0, 255,  cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# bluring \n",
    "kernel_size = 3\n",
    "blur_thresh_x = cv2.GaussianBlur(thresh_x,(kernel_size, kernel_size),0)\n",
    "blur_thresh_y = cv2.GaussianBlur(thresh_y,(kernel_size, kernel_size),0)\n",
    "\n",
    "# Run Hough on edge detected image\n",
    "\n",
    "rho = 1  # distance resolution in pixels of the Hough grid   \n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 15  # minimum number of votes (intersections in Hough grid cell)  \n",
    "min_line_length = 200  # minimum number of pixels making up a line   \n",
    "max_line_gap = 1  # maximum gap in pixels between connectable line segments   \n",
    "line_image = np.copy(gray) * 0  # creating a blank to draw lines on\n",
    "\n",
    "# Vertical lines\n",
    "vertical_lines = cv2.HoughLinesP(blur_thresh_x, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "if vertical_lines is not None:\n",
    "    for line in vertical_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            # here it's possible to add a selection of only vertical lines\n",
    "            if np.abs(y1-y2)> 0.1 * np.abs(x1-x2):\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),255,5)\n",
    "                \n",
    "                \n",
    "                \n",
    "\n",
    "# Horizontal lines\n",
    "horizontal_lines = cv2.HoughLinesP(blur_thresh_y, rho, theta, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "\n",
    "if horizontal_lines is not None:\n",
    "    for line in horizontal_lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            # here it's possible to add a selection of only horizontal lines\n",
    "            if np.abs(x1-x2)> 0.1 * np.abs(y1-y2):\n",
    "                cv2.line(line_image,(x1,y1),(x2,y2),255,5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold\n",
    "thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "# remove lines\n",
    "clean_thresh = cv2.subtract(thresh, line_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search the phrases\n",
    "dilatation_type = cv2.MORPH_RECT\n",
    "horizontal_dilatation = 20 #This is the gap. 20 for the first image, 10 for the second image\n",
    "vertical_dilatation = 1\n",
    "element = cv2.getStructuringElement(dilatation_type, (2*horizontal_dilatation + 1, 2*vertical_dilatation+1), (horizontal_dilatation, vertical_dilatation))\n",
    "dilatation_thresh = cv2.dilate(clean_thresh, element)\n",
    "\n",
    "# Fill\n",
    "filled_tresh = dilatation_thresh.copy()\n",
    "contours, hierarchy = cv2.findContours(dilatation_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for cnt in contours:\n",
    "    cv2.drawContours(filled_tresh, [cnt], -1, 255, cv2.FILLED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding boxes\n",
    "bounding_box1 = filled_tresh.copy()\n",
    "contours, hierarchy = cv2.findContours(bounding_box1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(bounding_box1,(x,y),(x+w,y+h),255,cv2.FILLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPEAT Draw bounding boxes and Find the mean text width\n",
    "mean_bb_width = 0 # mean bounding box width\n",
    "\n",
    "bounding_box2 = bounding_box1.copy()\n",
    "\n",
    "contours, hierarchy = cv2.findContours(bounding_box2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "num_cnt=0\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(bounding_box2,(x,y),(x+w,y+h),255,cv2.FILLED)\n",
    "    mean_bb_width = mean_bb_width+w\n",
    "    num_cnt=num_cnt+1\n",
    "    \n",
    "mean_bb_width=mean_bb_width/num_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define title what has width bigger than 1.5* mean_width \n",
    "min_title_width = 1.5 * mean_bb_width\n",
    "\n",
    "raw_title = np.copy(gray) * 0  \n",
    "raw_text = np.copy(gray) * 0  \n",
    "\n",
    "# separate titles from phrases\n",
    "contours, hierarchy = cv2.findContours(bounding_box2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    if w >=min_title_width :\n",
    "        cv2.drawContours(raw_title, [cnt], -1, 255, cv2.FILLED)\n",
    "    else :\n",
    "        cv2.drawContours(raw_text, [cnt], -1, 255, cv2.FILLED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_out = image.copy()\n",
    "\n",
    "# Closing parameters\n",
    "horizontal_closing = 1 \n",
    "vertical_closing = 20\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT,(horizontal_closing,vertical_closing))\n",
    "\n",
    "# Processing titles\n",
    "# Closing\n",
    "closing_title = cv2.morphologyEx(raw_title, cv2.MORPH_CLOSE, kernel)\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(closing_title, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Draw bounding boxes\n",
    "bounding_title = closing_title.copy()\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(image_out,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "# Processing text\n",
    "# Closing\n",
    "closing_text = cv2.morphologyEx(raw_text, cv2.MORPH_CLOSE, kernel)\n",
    "# Find contours\n",
    "contours, hierarchy = cv2.findContours(closing_text , cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Draw bounding boxes\n",
    "bounding_text = closing_text.copy()\n",
    "for cnt in contours:\n",
    "    x,y,w,h = cv2.boundingRect(cnt)\n",
    "    cv2.rectangle(image_out,(x,y),(x+w,y+h),(0,255,0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the image in large size\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(cv2.cvtColor(image_out, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
